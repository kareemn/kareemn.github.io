<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Kareem Nassar — AI, Speech & Real‑Time Translation</title>
    <meta name="description" content="Kareem Nassar is an AI engineer and founder focused on real‑time speech‑to‑speech translation, ASR, and low‑latency voice systems. Selected projects, demos, and writing." />

    <!-- Open Graph / Twitter -->
    <meta property="og:title" content="Kareem Nassar — AI, Speech & Real‑Time Translation" />
    <meta property="og:description" content="Projects across speech, reinforcement learning, and realtime systems." />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://kareemn.github.io/" />
    <meta property="og:image" content="/images/og-card.jpg" />
    <meta name="twitter:card" content="summary_large_image" />

    <!--     <link rel="stylesheet" href="stylesheets/styles.css" /> -->
    <link rel="stylesheet" href="stylesheets/pygment_trac.css" />
    <style>
      :root {
        --bg: #0b0c10;
        --card: #111316;
        --fg: #e6edf3;
        --muted: #a9b1ba;
        --link: #79c0ff;
        --accent: #9bcdff;
        --border: #232a31;
      }
      @media (prefers-color-scheme: light) {
        :root { --bg:#ffffff; --card:#f8fafc; --fg:#0f172a; --muted:#475569; --link:#0ea5e9; --accent:#0369a1; --border:#e2e8f0; }
      }
      html, body { height: 100%; }
      body { margin: 0; font: 16px/1.6 system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, Apple Color Emoji, Segoe UI Emoji; color: var(--fg); background: var(--bg); }
      a { color: var(--link); text-decoration: none; }
      a:hover { text-decoration: underline; }
      .wrapper { max-width: 960px; padding: 2rem; margin: 0 auto; }
      header { display: grid; grid-template-columns: 1fr; gap: 1rem; margin-bottom: 2rem; }
      .brand { display: flex; align-items: center; justify-content: space-between; gap: 1rem; }
      .brand h1 { font-size: clamp(1.5rem, 1.2rem + 2vw, 2.5rem); margin: 0; }
      .tag { color: var(--muted); margin: 0; }
      nav { display: flex; gap: 1rem; flex-wrap: wrap; }
      .nav-link { padding: .5rem .75rem; border: 1px solid var(--border); border-radius: 999px; background: linear-gradient(180deg, rgba(255,255,255,0.02), rgba(0,0,0,0.02)); }
      .hero { border: 1px solid var(--border); background: var(--card); padding: 1.25rem; border-radius: 16px; }
      .hero p { margin: .5rem 0; }
      section { border-top: 1px solid var(--border); padding-top: 2rem; margin-top: 2rem; }
      h2, h3 { margin: 0 0 .75rem; }
      .meta { color: var(--muted); font-size: .9rem; margin-bottom: .5rem; }
      .video-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; border: 1px solid var(--border); border-radius: 12px; background:#000; }
      .video-container iframe { position: absolute; inset: 0; width: 100%; height: 100%; border: 0; }
      img { max-width: 100%; height: auto; border: 1px solid var(--border); border-radius: 12px; }
      ul { margin: .5rem 0 1rem 1.25rem; }
      footer { color: var(--muted); padding: 3rem 0; text-align: center; }
      .grid { display: grid; grid-template-columns: 1fr; gap: 1.25rem; }
      @media (min-width: 720px) { .grid { grid-template-columns: 1fr 1fr; } }
      .chip { display:inline-block; font-size:.85rem; padding:.15rem .5rem; border:1px solid var(--border); border-radius:6px; color:var(--muted); margin-right:.25rem; }
      .sr-only{ position:absolute; clip:rect(1px,1px,1px,1px); padding:0; border:0; height:1px; width:1px; overflow:hidden; }
    </style>

    <!-- JSON-LD (Person) -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Kareem Nassar",
      "url": "https://kareemn.github.io/",
      "sameAs": [
        "https://github.com/kareemn",
        "https://www.linkedin.com/in/kareemnassar",
        "https://angel.co/knassar"
      ],
      "jobTitle": "Founder / AI Engineer",
      "worksFor": {"@type":"Organization","name":"EzDubs"}
    }
    </script>
  </head>
  <body>
    <a class="sr-only" href="#content">Skip to content</a>
    <div class="wrapper">
      <header>
        <div class="brand">
          <div>
            <h1>Kareem Nassar</h1>
            <p class="tag">AI engineer building real‑time speech systems • founder @ EzDubs</p>
          </div>
          <nav aria-label="Primary">
            <a class="nav-link" href="https://github.com/kareemn" rel="me noopener" target="_blank">GitHub</a>
            <a class="nav-link" href="http://angel.co/knassar" rel="noopener" target="_blank">AngelList</a>
            <a class="nav-link" href="http://www.linkedin.com/in/kareemnassar" rel="me noopener" target="_blank">LinkedIn</a>
          </nav>
        </div>
        <div class="hero">
          <p><strong>Now:</strong> co‑founding <em>EzDubs</em> — real‑time speech‑to‑speech translation that preserves speaker's voice with low latency. Previously led/implemented ASR and voice systems across startups and large‑scale deployments.</p>
          <p><span class="chip">ASR</span> <span class="chip">S2ST</span> <span class="chip">Latency</span> <span class="chip">Kubernetes</span> <span class="chip">PyTorch</span></p>
        </div>
      </header>

      <main id="content">
        <section id="smartmiq">
          <h2>Smartmiq Desktop Assistant</h2>
          <p class="meta">2021 • PyTorch (Transducer), macOS UI</p>
          <div class="grid">
            <div>
              <p>Spotlight‑style voice assistant for desktop. Trigger actions hands‑free (search, reply to Slack, etc.). I trained my own ASR based on a transducer architecture for tighter control over latency and accuracy.</p>
              <p><em>What I learned:</em> voice on laptops/desktops is useful but often slower than typing in public; UX must bias toward zero‑friction hybrid input (keyboard + voice), and ASR needs strong endpointing.</p>
            </div>
            <div>
              <figure>
                <img loading="lazy" src="images/smartmiq_search_google.gif" alt="Smartmiq demo: voice search triggering Google results" />
              </figure>
              <p style="margin:.5rem 0 0; color:var(--muted)">Replying to Slack by voice:</p>
              <img loading="lazy" src="images/smartmiq_slack_reply.gif" alt="Smartmiq demo: replying to Slack messages with voice" />
            </div>
          </div>
        </section>

        <section id="pong-rl">
          <h2>Deep RL plays Pong</h2>
          <p class="meta">SAC • CNN policy/critic • PyTorch</p>
          <p>Implemented Soft Actor‑Critic with an AtariNet‑style convolutional encoder. Training leveraged replay, MC rollouts, and importance sampling. After tuning entropy targets and augmentation, the agent achieved stable Pong gameplay.</p>
          <div class="video-container" aria-label="YouTube demo: RL agent playing Pong">
            <iframe src="https://www.youtube-nocookie.com/embed/bMo1Gg-ymD8" title="Pong RL demo" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
          <p>Training code: <a href="https://gist.github.com/kareemn/c760f652ffb62cb565f99f926d807025" target="_blank" rel="noopener">gist</a></p>
        </section>

        <section id="noise-suppression">
          <h2>Noise Suppression Neural Network</h2>
          <p class="meta">2020 • VoiceFilter‑style masking</p>
          <p>Learned a spectral mask to suppress non‑speech noise, inspired by Google’s VoiceFilter. The model improves intelligibility in common home/office environments.</p>
          <div class="video-container" aria-label="YouTube demo: noise suppression before/after">
            <iframe src="https://www.youtube-nocookie.com/embed/Mon3kjfvdx0" title="Noise suppression demo" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </section>

        <section id="rover">
          <h2>Rover — Music Visualizer via GAN</h2>
          <p class="meta">Rust • DCGAN latent exploration</p>
          <p>Mapped audio frequency features to a smoothed latent walk through a pretrained art‑DCGAN to generate synchronized visuals in real time.</p>
          <ul>
            <li>Compute frequency components per frame</li>
            <li>Integrate with previous latent for temporal smoothness</li>
            <li>Render GAN output to framebuffer</li>
          </ul>
          <div class="video-container" aria-label="YouTube demo: Rover GAN visualizer">
            <iframe src="https://www.youtube-nocookie.com/embed/a9yJmaswq2o" title="Rover GAN Visualizer" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
          <p>Code: <a href="https://github.com/kareemn/rover" target="_blank" rel="noopener">github.com/kareemn/rover</a></p>
        </section>

        <section id="meeting-assistant">
          <h2>Meeting Voice Assistant (Zoom/Meet/Webex)</h2>
          <p class="meta">2018 • Workfit/Voicera/Voicea • Kubernetes</p>
          <p>Before high‑quality meeting audio APIs existed, I emulated webcam/mic drivers in a Dockerized headless Chrome to capture >16kHz audio for wake‑word and ASR, then scaled it across a Kubernetes cluster. We also used a virtual webcam to demo the bot live, a surprisingly effective growth loop.</p>
          <div class="video-container" aria-label="YouTube demo: meeting assistant in Zoom">
            <iframe src="https://www.youtube-nocookie.com/embed/1FbBXDxFG7g" title="Zoom meeting assistant demo" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </section>

        <section id="poynt">
          <h2>Poynt Nay‑Nay</h2>
          <p class="meta">2015 • Payment terminal OS • Remote updates</p>
          <p>Built remote OS/app update tooling for payment terminals; for a stress test we pushed a music video to all test devices at once — chaos ensued.</p>
          <div class="video-container" aria-label="YouTube demo: Poynt Nay-Nay">
            <iframe src="https://www.youtube-nocookie.com/embed/7pg6mZ9HXU4" title="Poynt Nay-Nay" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
        </section>
      </main>

      <footer>
        <p><small>© <span id="y"></span> Kareem Nassar • Built with plain HTML/CSS, no framework</small></p>
      </footer>
    </div>

    <script>
      // Small niceties: current year and reduced‑motion pause for videos if desired
      document.getElementById('y').textContent = new Date().getFullYear();
    </script>
  </body>
</html>
